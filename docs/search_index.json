[["index.html", "Econometría 2 Prefacio", " Econometría 2 Andrés Vargas 2022-04-27 Prefacio Notas de clase de la asignatura Econometría 2, del programa de Economía de la Universidad del Norte. Están bajo permanente revisión y actualización. Comentarios o sugerencias a andresmv@uninorte.edu.co "],["sobre-el-autor.html", "Sobre el autor Andrés Vargas", " Sobre el autor Andrés Vargas Economista, profesor adscrito al departamento de economía de la Universidad del Norte, Colombia. "],["introducción.html", "Introducción", " Introducción Este curso se divide en dos partes. En la primera se aborda la idea de inferencia causal en estructuras de datos transversales y longitudinales. A partir de las propiedades del estimador de Mínimos Cuadrados Ordinarios se identifican las circunstancias bajo las cuales se le puede dar una interpretación causal a los parámetros estimados. Cuando no es posible, se examinan métodos alternativos de estimación. La segunda parte del curso introduce a las series de tiempo. Tomando como punto de partida los conceptos de dependencia débil y estacionariedad se estudian modelos dinámicos univariados y multivariados. "],["el-modelo-de-regresión-lineal-y-el-estimador-mco.html", "Capítulo1 El modelo de regresión lineal y el estimador MCO 1.1 La mecánica del estimador MCO 1.2 Estimador 1.3 Estimador MCO", " Capítulo1 El modelo de regresión lineal y el estimador MCO La tabla muestra los resultados para la estimación del siguiente modelo \\[\\begin{equation} sales=\\beta_0+\\beta_1price+\\beta_2advert+e \\end{equation}\\] Donde sales son los ingresos mensuales de una compañía, en miles de dólares, price es un índice de precios de todos los productos vendidos, y advert es el gasto mensual en publicidad, también en miles de dólares. Table 1.1: Modelo básico de regresión lineal Coefficient Std. Error t-value p-value (Intercept) 118.914 6.352 18.722 0.000 price -7.908 1.096 -7.215 0.000 advert 1.863 0.683 2.726 0.008 Interprete los resultados Explique la magnitud del coeficiente estimado Explique cada una de las columnas ¿Son las variables significativas? Si la respuesta es afirmativa, ¿esto que quiere decir? Desde el punto de vista práctico, los números que mas nos interesan en la tabla son la estimación puntual del coeficiente y el error estándar. Con el primero examinamos la dirección y magnitud del efecto de \\(x\\) sobre \\(y\\), con el segundo tenemos una idea de la precisión de la estimación y nos permite indagar si el valor estimado del parámetro es diferente de cero, en términos estadísticos. Veamos esto en detalle 1.1 La mecánica del estimador MCO Suponga que usted tiene los siguientes datos La regresión lineal no es más que buscar la línea que mejor se ajuste a estos datos. La forma más simple de estimar los parámetros es usando el estimador de Mínimos Cuadrados Ordinarios, MCO. La idea es la siguiente. Planteamos una relación lineal entre \\(y\\) y \\(x\\) \\[\\begin{equation} y=\\alpha+\\beta x+e \\end{equation}\\] En esta ecuación \\(\\alpha\\) es el intercepto y \\(\\beta\\) la pendiente. El término \\(e\\) lo llamamos el error. Note que el error recoge la diferencia entre lo que observamos de \\(y\\) y lo que \\(x\\) predice que será \\(y\\). Si \\(\\alpha=100\\) y \\(\\beta=10\\) entonces podemos decir que si \\(x=10\\) entonces \\(y=200\\). Sin embargo, al observar la gráfica se dará cuenta que hay muchas puntos donde \\(x=10\\) pero \\(y\\neq200\\). Esa diferencia es \\(e\\) ¿Por qué podría darse esa diferencia entre lo predicho y lo observado? Varias razones Hay otras variables, ej. \\(z\\), que pueden afectar el comportamiento de \\(y\\), y que no hemos incluido Variabilidad aleatoria. Digamos que \\(\\hat{y}\\) es la línea de regresión, y esta es igual a \\[\\begin{equation} \\hat{y}=\\hat{\\alpha}+\\hat{\\beta}x \\end{equation}\\] La distancia entre cada punto y la línea de regresión es \\[\\begin{equation} \\hat{e}_i=y_i-\\hat{y}_i=y_i-\\hat{\\alpha}-\\hat{\\beta}x_i \\end{equation}\\] Los parámetros que producen la mejor línea son aquellos que minimizan la suma de los residuales al cuadrado \\[\\begin{equation} SSE=\\sum_i\\hat{e}_i^2 \\end{equation}\\] Lo anterior quiere decir, que aún cuando hay muchas líneas que recogen la relación positiva entre nuestras variables, hay una que es la mejor de todas El estimador MCO, puede entenderse como un algoritmo para encontrar la mejor línea entre todas las posibles. Donde mejor significa la que minimiza la suma de residuales al cuadrado. En términos más simples, la línea que se equivoca menos. 1.2 Estimador Decimos que estimamos los parámetros \\(\\boldsymbol{\\beta}\\) porque partimos de la idea de que nuestras variables \\(y\\) y \\(x\\) son variables que representan a alguna población. Sin embargo, nosotros tenemos una muestra particular. Es decir, nuestros datos son una única muestra de muchas muestras posibles que pudimos haber obtenido de la misma población. Por ejemplo, supongamos que nuestra población de interés son los estudiantes de economía de la Universidad del Norte, \\(N=180\\). Sea \\(PGA\\) el promedio académico de cada estudiante. Queremos calcular el promedio de \\(PGA\\) para la población de estudiantes del programa de economía. El parámetro poblacional es el PGA promedio para todos los estudiantes, \\(\\mu=E(PGA)\\). Por alguna razón, no es posible obtener ese dato para todos los estudiantes, sino que tenemos a nuestra disposición una muestra aleatoria de 50 estudiantes, \\(n_1=50\\). Con esta muestra calculamos (estimamos) un PGA promedio de 3.6. Llamemos a esta estimación \\(\\hat{\\mu}_1=\\bar{PGA}_1=\\dfrac{1}{n_1}\\sum_{i=1}^{n_1}PGA_i\\) Imagine que hubiésemos obtenido una muestra diferente, \\(n_2=50\\), y con esta muestra calculamos un \\(\\hat{\\mu}_2=3.5\\). Debe ser claro que siempre que estimamos, el número que obtenemos va a depender de la muestra que tengamos. La variabilidad muestral es inevitable, así que lo importante es tenerla en cuenta para poder evaluar que tan bueno es nuestro proceso de estimación. Así, mientras \\(\\mu\\) es un parámetro poblacional \\(\\hat{\\mu}\\) es un estimador de dicho parámetro poblacional. El parámetro poblacional es una característica no aleatoria de la población, mientras que el estimador si es aleatorio. \\(\\mu\\) está fijo y \\(\\hat{\\mu}\\) varía entre muestras. Veamos Supongamos que podemos tomar 100 muestras diferentes de tamaño 50. Para cada muestra calculamos el PGA promedio, \\(\\mu_i\\) donde \\(i=1,...100\\). Veamos como se distribuye el PGA promedio estimado en cada muestra. library(msm) set.seed(12345) #para iniciar la obtención de números aleatorios pga&lt;-rtnorm(180,mean=3.6,sd=0.4,lower=1,upper=5) nrsim&lt;-100 vpga&lt;-numeric(nrsim) for (i in 1:nrsim){ pgasi&lt;-sample(pga,50,replace=TRUE,prob=NULL) vpga[i]&lt;-mean(pgasi) } library(ggplot2) vpgadf&lt;-data.frame(vpga) ggplot(vpgadf,aes(x=vpga))+geom_density(fill=&quot;lightblue&quot;,alpha=0.4)+geom_vline(xintercept=mean(vpga),linetype=4)+theme_minimal()+labs(title=&quot;Distribución del promedio de PGA&quot;,subtitle=&quot;100 muestras diferentes&quot;,x=&quot;PGA promedio&quot;) El promedio de las estimaciones en las 100 muestras, \\(\\dfrac{1}{100}\\sum_{i=1}^{100}\\hat{\\mu}_i\\), es round(mean(vpga),digits=2) ## [1] 3.65 Este valor lo comparamos con el valor del parámetro poblacional, que en este caso es round(mean(pga),digits=2) ## [1] 3.65 Así, podemos decir que nuestro procedimiento para estimar el promedio de PGA a partir de una muestra es bueno, pues en promedio nos permitirá obtener el valor verdadero. En otras palabras \\[\\begin{equation} \\dfrac{1}{100}\\sum_{i=1}^{100}\\hat{\\mu}_i=\\mu \\end{equation}\\] 1.3 Estimador MCO Ya sabemos que el estimador MCO consiste en obtener los parámetros que minimizan la suma de los errores al cuadrado. El método de mínimos cuadrados consiste en obtener los valores de los parámetros \\(\\boldsymbol{\\beta}\\) que minimizan \\[SSE(\\beta)=\\sum_{i=1}^{n}(y_i-\\beta_0-\\beta_1x_{i1}-\\beta_2x_{i2}-...-\\beta_kx_{ik})^2\\] Si llamamos \\(\\boldsymbol{\\hat{\\beta}}\\) a los parámetros estimados con los datos que tenemos, entonces sabemos que la formula para computarlos es, en términos matriciales1 \\[\\begin{equation} \\hat{\\boldsymbol{\\beta}}=\\mathbf{(X&#39;X)^{-1}X&#39;Y} \\end{equation}\\] Donde \\(\\mathbf{X}\\) y \\(\\mathbf{Y}\\) son las matrices de datos, de dimensiones \\(nxk\\) y \\(nx1\\), respectivamente. Para poner las cosas simples, supongamos que tenemos el siguiente modelo \\[\\begin{equation} y=\\beta_0+\\beta_1x_1+\\beta_2x_2+e \\end{equation}\\] De la sección anterior sabemos que los estimadores (\\(\\hat{\\beta_0},\\hat{\\beta_1},\\hat{\\beta_2}\\)) son variables aleatorias. Toman diferentes valores en diferentes muestras, y sus valores son desconocidos hasta que la muestra es obtenida y sus valores computados. La distribución muestral del estimador MCO describe como varían estos estimadores sobre todas las muestras posibles. Las propiedades muestrales del estimador hacen referencia a la media y la varianza de de dicha distribución. Si la media de la distribución es igual al valor del parámetro poblacional, entonces decimos que el estimador es insesgado. En nuestro ejemplo de PGA esto es lo mismo que decir \\(E(\\hat{\\mu})=\\mu\\). La varianza de la distribución nos dice que tanto cambia el estimador entre muestras. Entre más cambie entre muestras, menos confiable es el estimador, menos preciso. 1.3.1 Simulación Simulemos un proceso y veamos estas ideas de forma precisa. Digamos que la ecuación poblacional es \\[\\begin{equation} Y=5+2.5X_1+3X_2+e \\end{equation}\\] y que nuestra población es \\(N=10,000\\). Como antes, supongamos que no conocemos el valor de los parámetros y los estimamos a partir de alguna muestra. Obtenemos muestras de tamaño \\(n=100\\), aproximadamente. Lo que queremos ver es si nuestro procedimiento nos permite obtener los parámetros verdaderos. Simularemos \\(1000\\) muestras library(mvtnorm) N&lt;-10000 coefs&lt;-cbind(&quot;hat_beta_1&quot; = numeric(1000), &quot;hat_beta_2&quot; = numeric(1000)) #Vector que guardará los coeficientes set.seed(1) # permite reproducir los resultados X &lt;- rmvnorm(N, c(50, 100), sigma = cbind(c(10, 2.5), c(2.5, 10))) # generamos X1 y X2 e &lt;- rnorm(N, sd = 5) Y &lt;- 5 + 2.5 * X[, 1] + 3 * X[, 2] + e xdf&lt;-data.frame(X,Y) nrsim&lt;-1000 #obtenemos 1000 muestras de nuestra población for (i in 1:nrsim){ dfs&lt;-sample(c(TRUE,FALSE),nrow(xdf),replace=TRUE,prob=c(0.01,0.99)) #muestra aleatoria, n aprox 100 dfs&lt;-xdf[dfs,] ols&lt;-lm(Y~X1+X2,data=dfs) #estimamos para cada muestra generada coefs[i,]&lt;-coef(ols)[-1] # el valor estimado de b1 y b2 en cada muestra se lleva al vector coefs } coefs.df&lt;-data.frame(coefs) Calculemos ahora el promedio de los valores estimados \\(\\hat{\\beta_1}\\) y \\(\\hat{\\beta_2}\\) library(dplyr) msd&lt;-coefs.df%&gt;%summarise(b1m=mean(coefs.df$hat_beta_1), b2m=mean(coefs.df$hat_beta_2), b1sd=sd(coefs.df$hat_beta_1), b2sd=sd(coefs.df$hat_beta_1) ) kable(msd, caption=&quot;Promedio y desviación estándar de los estimadores&quot;, col.names=c(&quot;Media b1&quot;, &quot;Media b2&quot;, &quot;SD b1&quot;, &quot;SD b2&quot;), align=&quot;c&quot;, digits=2) Table 1.2: Promedio y desviación estándar de los estimadores Media b1 Media b2 SD b1 SD b2 2.5 2.99 0.17 0.17 Veamos la distribución del estimador \\(\\hat{\\beta}_1\\) ggplot(coefs.df,aes(x=hat_beta_1))+geom_density(fill=&quot;lightblue&quot;,alpha=0.4)+ geom_vline(xintercept=mean(coefs.df$hat_beta_1),linetype=4)+theme_minimal()+ labs(title=&quot;Distribución del promedio del estimador&quot;,subtitle=&quot;1000 muestras diferentes&quot;,x=expression(beta[1]*estimado)) Con cada muestra se estima un valor diferente del parámetro de interés, pero si promediamos todas las estimaciones encontramos que \\(\\dfrac{1}{1000}\\sum_{i=1}^{1000}\\hat{\\beta}_{1i}=2.5\\). Este es exactamente el valor del parámetro poblacional. Podemos decir entonces que nuestro estimador es insesgado. Ejercicio Replique la actividad anterior, pero ahora varíe el tamaño de muestra: i) \\(n\\approx50\\); ii) \\(n\\approx1000\\). Compare la media y la desviación estándar del estimador ¿Qué puede concluir? "],["estimador-mco-propiedades.html", "Capítulo2 Estimador MCO: Propiedades 2.1 El valor esperado del estimador MCO 2.2 La varianza del estimador en datos de corte transversal 2.3 Error estándar e inferencia 2.4 Ejercicio", " Capítulo2 Estimador MCO: Propiedades Nuestro punto de partida es el modelo poblacional \\[\\begin{equation} \\tag{1} y=\\beta_1+\\beta_2x_2+\\beta_3x_3+...+\\beta_kx_k+u \\end{equation}\\] Donde donde las variables \\(y,x_2,...,x_k\\) son aleatorias y observables, y \\(u\\) es un error no observable. Los parámetros \\(\\beta_1,\\beta_2,...,\\beta_k\\) son los que queremos estimar. El error \\(u\\) recoge perturbaciones aleatorias, y también todo aquello que es importante para explicar \\(y\\) pero que no hemos incluido explícitamente en el modelo, es decir variables omitidas. La idea de población no hace referencia, necesariamente, a una población física en el mundo real. Significa que si tenemos una observación para el individuo i, \\((y_i,x_i)\\), esta la consideramos como la realización de una función de probabilidad conjunta \\(F(y,x)\\). Nosotros no conocemos \\(F\\), y el propósito de la inferencia es aprender sus características a partir de una muestra, es decir del conjunto particular de datos que tenemos. Lo anterior significa que a partir de nuestros datos estimamos los valores de \\(\\boldsymbol{\\beta}\\), y a estos los llamamos \\(\\hat{\\boldsymbol{\\beta}}\\) El estimador MCO consiste en estimar dichos parámetros a partir de encontrar el valor de ellos tales que se minimiza la diferencia al cuadrado entre el valor observado y el valor predicho, con una muestra particular de datos. Esto quiere decir que son aquellos que minimizan la expresión \\[\\begin{equation} \\tag{2} \\sum_i^n(y_i-\\hat{\\beta_1}-\\hat{\\beta_2}x_{i2}-...-\\hat{\\beta_k}x_{ik})^2 \\end{equation}\\] Donde \\(i=1,...,n\\) identifica cada observación en la muestra. Al tomar las condiciones del primer orden obtenemos \\[\\begin{align} \\tag{3} \\sum_i^n(y_i-\\hat{\\beta_1}-\\hat{\\beta_2}x_{i2}-...-\\hat{\\beta_k}x_{ik})&amp;=0\\\\ \\sum_i^nx_{i2}(y_i-\\hat{\\beta_1}-\\hat{\\beta_2}x_{i2}-...-\\hat{\\beta_k}x_{ik})&amp;=0\\\\ .&amp;\\\\ .&amp;\\\\ .&amp;\\\\ \\sum_i^nx_{ik}(y_i-\\hat{\\beta_1}-\\hat{\\beta_2}x_{i2}-...-\\hat{\\beta_k}x_{ik})&amp;=0 \\end{align}\\] Fíjese que tenemos un sistema de \\(k\\) ecuaciones con \\(k\\) incognitas. En términos matriciales esto lo podemos escribir como \\[\\begin{equation} \\tag{4} \\mathbf{X&#39;}(\\mathbf{y}-\\mathbf{X}\\boldsymbol{\\hat{\\beta}})=0 \\end{equation}\\]. Donde \\(\\mathbf{X}\\) es \\(n\\times k\\) y recoje los datos de las variables independientes, mientras que \\(\\mathbf{y}\\) es \\(n\\times 1\\) y contiene los valores de la variable dependiente, y es la matriz de parámetros estimados, de dimensión \\(k\\times 1\\). La expresión anterior es equivalente a \\[\\begin{equation} \\tag{5} \\mathbf{(X&#39;X)}\\hat{\\boldsymbol{\\beta}}=\\mathbf{X&#39;y} \\end{equation}\\] Si la matriz \\(\\mathbf{(X&#39;X)}\\) es invertible entonces podemos premultiplicar a ambos lados por \\(\\mathbf{(X&#39;X)}^{-1}\\) y obtenemos \\[\\begin{equation} \\tag{6} \\hat{\\boldsymbol{\\beta}}=\\mathbf{(X&#39;X)}^{-1}\\mathbf{X&#39;y} \\end{equation}\\] La matriz \\(\\mathbf{(X&#39;X)}\\) es invertible si no hay colinealidad perfecta entre las variables. Como el valor estimado de los parámetros se obtuvo de una muestra particular de datos entonces debemos tener en cuenta que pudimos haber observado una muestra diferente, con la cual el valor puntual estimado habría sido diferente. Nuestro objetivo es obtener las propiedades estadísticas del estimador 2.1 El valor esperado del estimador MCO S1 Modelo poblacional \\[\\begin{equation} y=\\beta_1+\\beta_2x_2+\\beta_3x_3+...+\\beta_kx_k+u \\end{equation}\\] S2 Tenemos una muestra aleatoria de tamaño \\(n\\), \\(\\{(x_{i1},x_{i2},...,x_{ik}):i=1,2,...,n\\}\\), es decir que las observaciones son independientes e identicamente distribuidas. Por ejemplo, el ingreso y nivel educativo del individuo \\(i\\) es independiente del individuo \\(j\\). S3 No hay colinealidad perfecta, y por lo tanto \\(\\mathbf{(X&#39;X)}\\) es invertible S4 \\(E(u|x_1,x_2,...,x_k)=0\\) El valor esperado condicional del error es cero. Es decir que el error no está relacionado con las variables independientes. Bajo estos supuestos, podemos mostrar que \\[\\begin{equation} \\tag{7} E(\\hat{\\boldsymbol{\\beta}}|\\mathbf{X})=0 \\end{equation}\\] Veamos. Primero tomemos el valor esperado condicional en la ecuación \\((6)\\) \\[\\begin{equation} \\tag{8} E(\\hat{\\boldsymbol{\\beta}}|\\mathbf{X})=\\mathbf{(X&#39;X)}^{-1}E(\\mathbf{X&#39;y}|\\mathbf{X}) \\end{equation}\\] Como \\(\\mathbf{y}=\\mathbf{X}\\boldsymbol{\\beta}+u\\), entonces \\[\\begin{equation} \\tag{9} E(\\hat{\\boldsymbol{\\beta}}|\\mathbf{X})=\\mathbf{(X&#39;X)}^{-1}\\mathbf{X&#39;X}\\boldsymbol{\\beta}+\\mathbf{(X&#39;X)}^{-1}\\mathbf{X&#39;}E(u|\\mathbf{X}) \\end{equation}\\] Luego, si se cumple S4 \\[\\begin{equation} \\tag{10} E(\\hat{\\boldsymbol{\\beta}}|\\mathbf{X})=\\boldsymbol{\\beta} \\end{equation}\\] Es decir que el estimador es insesgado. 2.2 La varianza del estimador en datos de corte transversal S5 Homocedasticidad, \\(Var(u|\\mathbf{X})=\\sigma^2\\). Es decir que la varianza condicional del error es la misma para todos los valores de las variables explicativas. Con S5 entonces podemos mostrar que \\[\\begin{equation} \\tag{11} Var(\\hat{\\boldsymbol{\\beta}}|\\mathbf{X})=\\sigma^2\\mathbf{(X&#39;X)}^{-1} \\end{equation}\\] Para entenderlo mejor, la varianza para un \\(\\beta_j\\) particular sería \\[\\begin{equation} Var(\\hat{\\beta_j}|\\mathbf{X})=\\dfrac{\\sigma^2}{\\sum_{i=1}^n(x_{ij}-\\bar{x}_j)^2(1-R_j^2)} \\end{equation}\\] Donde \\(R_j^2\\) es el \\(R\\)-cuadrado de una regresión de \\(x_j\\) contra las demás independiente. Entre más correlacionada esté \\(x_j\\) con las demás variables, mayor será el \\(R\\)-cuadrado La varianza depende de tres cosas La varianza del error \\(\\sigma^2\\). Esto es una característica de la población. Si se agregan más variables esta podría reducirse. Sin embargo, si el modelo ya incluye las variables relevantes, entonces ya no habría nada que agregar La variabilidad muestral de \\(x_j\\): \\(\\sum_{i=1}^n(x_{ij}-\\bar{x}_j)^2\\) Entre mayor sea la variabilidad menor es la varianza. Al aumentar el tamaño de muestra la variabilidad se incrementa y disminuye la varianza del estimador El grado de relación lineal entre las variables independientes: \\(R_j^2\\). Entre mayor sea la correlación la varianza es más grande. Una alta correlación siginifica que a pesar de tener muchos datos tengo poca información 2.3 Error estándar e inferencia Como \\(\\sigma^2\\) no es observable \\(Var(\\hat{\\beta_j}|\\mathbf{X})\\) no es computable. Para ello debo tener un estimador insesgado de \\(\\sigma^2\\), esto es un \\(\\hat{\\sigma}^2\\) tal que \\(E(\\hat{\\sigma}^2)=\\sigma^2\\), y por lo tanto que tengamos un estimador insesgado de la varianza del estimador Como \\(\\sigma^2=E(u^2)\\), entonces un estimador es la media muestral, promedio, de los residuales \\[\\begin{equation} \\hat{\\sigma}^2=\\dfrac{\\sum_{i=1}^n\\hat{u}_i^2}{n-k} \\end{equation}\\] Luego el error estándar es \\[\\begin{equation} \\tag{12} se(\\hat{\\beta})=\\dfrac{\\hat{\\sigma}}{\\sum_{i=1}^n(x_{ij}-\\bar{x}_j)^2(1-R_j^2)} \\end{equation}\\] Importante. La formula anterior es válida bajo el supuesto de homocedasticidad El próximo paso es hacer inferencia estadística, es decir la realización de pruebas de hipótesis. Para ello necesitamos la distribución muestral de \\(\\hat{\\beta_j}\\). De la ecuación \\((9)\\) es claro que la distribución muestral, condicionada en las independientes, depende del error. S5 El error se distribuye normal con media cero y varianza \\(\\sigma^2\\): \\(u\\sim N(0,\\sigma^2)\\) Bajo los supuestos anteriores y S5, tenemos entonces que \\[\\begin{equation} \\tag{13} \\hat{\\beta}_j\\sim N(\\beta,Var(\\hat{\\beta})) \\end{equation}\\] Luego \\[\\begin{equation} \\tag{14} \\dfrac{\\hat{\\beta}_j-\\beta_j}{sd(\\hat{\\beta}_j)}\\sim N(0,1) \\end{equation}\\] Para hacer pruebas de hipótesis sobre un solo parámetro usamos \\((14)\\) pero teniendo en cuenta que \\(sd(\\hat{\\beta})\\) no es observable, pero su estimación es el error estándar, de donde tenemos que \\[\\begin{equation} \\tag{15} \\dfrac{\\hat{\\beta}_j-\\beta_j}{se(\\hat{\\beta}_j)}\\sim t_{n-k} \\end{equation}\\] Ahora, para probar \\(H_0:\\beta_j=0\\) usamos la estadística \\(t\\equiv(\\hat{\\beta_j}-\\beta_{j,H_0})/se(\\hat{\\beta}_j)\\). Esta me dice que tanto se desvia el valor estimado del valor bajo la hipótesis nula en relación a la desviación estándar. Por ejemplo, si \\(t=1\\) decimos que el valor estimado es mayor a cero en una desviación estándar del estimador. Dado que se obtiene un valor puntual de \\(\\hat{\\beta_j}\\), pero sabemos que pudimos haber obtenido un valor diferente con otra muestra, entonce debemos examinar la distribución de \\(\\hat{\\beta}_j\\) para saber que tan probable es que hubiésemos obtenido un valor estimado de cero. La prueba \\(t\\) me permite responder esa pregunta Demostración Vamos a simular unos datos \\(Y=\\alpha+\\beta_{X1}X_1+\\beta_{X2}X_2+u\\). Empezaremos simulando un proceso con \\(\\alpha=5\\), \\(\\beta_{X1}=0.5\\), \\(\\beta_{X2}=3\\). Tomamos inicialmente una muestra \\(n\\approx 100\\), y estimamos los coeficientes vía MCO Simulamos los datos y tomamos una muestra library(mvtnorm) library(ggplot2) N&lt;-10000 coefs&lt;-cbind(&quot;hat_beta_1&quot; = numeric(1000), &quot;hat_beta_2&quot; = numeric(1000)) #Vector que guardará los coeficientes set.seed(1) # permite reproducir los resultados X &lt;- rmvnorm(N, c(50, 100), sigma = cbind(c(10, 2.5), c(2.5, 10))) # generamos X1 y X2 u &lt;- rnorm(N, sd = 5) Y &lt;- 5 + 0.5 * X[, 1] + 3 * X[, 2] + u xdf&lt;-data.frame(X,Y) dfs&lt;-sample(c(TRUE,FALSE),nrow(xdf),replace=TRUE,prob=c(0.01,0.99)) #muestra aleatoria, n aprox 100 dfs&lt;-xdf[dfs,] Estimamos por MCO model1&lt;-lm(Y~X1+X2,data=dfs) model1 Call: lm(formula = Y ~ X1 + X2, data = dfs) Coefficients: (Intercept) X1 X2 -12.4896 0.9628 2.9362 Calculamos el error estándar y el estadístico \\(t\\). Tenga en cuenta que para estimar la varianza del estimador necesitamos \\[\\hat{\\sigma}^2=\\dfrac{\\sum_{i}^{n}\\hat{u}_i}{n-k}\\] X1bar&lt;-mean(dfs$X1) sumX1sqr&lt;-sum((dfs$X1-X1bar)^2) Rsqrx1&lt;-summary(lm(X1~X2,data=dfs))$r.squared uhat&lt;-model1$residuals sigmahat&lt;-(sum(uhat^2))/(model1$df.residual)#Varianza estimada del error varhatb1hat&lt;-sigmahat/(sumX1sqr*(1-Rsqrx1))#Varianza estimada del estimador se&lt;-sqrt(varhatb1hat) se [1] 0.1990679 t&lt;-coef(model1)[2]/se t X1 4.836502 Hacemos la prueba de hipótesis \\(Ho:\\beta_{X1}=0\\) contra la alternativa \\(Ha:\\beta_{X1}\\neq0\\). Grafiquemos la distribución \\(t_{df}\\) con los grados de libertar correspondientes y veamos donde se ubica nuestro estadístico \\(t\\) funcShaded &lt;- function(x) { y &lt;- dt(x,df=87) y[x &gt; -2&amp;x&lt;2 ] &lt;- NA return(y) } tdst&lt;- ggplot(data.frame(x = c(-4, 4)), aes(x = x)) + stat_function(fun = dt, args = list(df = model1$df.residual)) tdst+theme_classic()+stat_function(fun=funcShaded,geom=&quot;area&quot;, fill=&quot;blue&quot;,alpha=0.2)+ annotate(&quot;text&quot;, x =-3 , y = 0.1,label=&quot;Area=0.25&quot;)+annotate(&quot;text&quot;, x =3 , y = 0.1,label=&quot;Area=0.25&quot;)+ labs(title=&quot;Zonas de rechazo al 5%, df=60&quot;,y=&quot;&quot;,x=&quot;&quot;) 2.4 Ejercicio 2.4.1 Retornos a la educación Ingrese a la carpeta Data en el repositorio y descargue la base de datos wagew.rda. Esta base contiene los datos de la GEIH 2019. La base tiene información para personas ocupadas cuya posición ocupacional es empleado de empresa particular o empleado del gobierno. Contiene las siguientes variables p6020: 1 hombre, 2 mujer p6040: edad en años p6210: nivel educativo más alto alcanzado. 1 ninguno, 3 primaria, 4 básica (6-9), 5 media (10-13), 6 superior o universitaria p6210s1: último grado aprobado impa: ingreso monetario mensual sy: años de escolaridad Su propósito es estimar el retorno a la educación, en otras palabras, en cuánto aumenta el ingreso por cada año adicional de educación. Para ello plantea una ecuación de Mincer de la forma \\[ ln(w_i)=\\alpha+\\beta_1S_i+\\beta_2Exp_i+\\beta_3Exp^2+\\gamma Mujer_i+e_i \\] Donde \\(ln(w_i)\\): logaritmo del ingreso laboral mensual \\(S_i\\): años de escolaridad \\(Exp\\): es la experiencia potencial en el mercado laboral, la cual se calcula como \\(edad-S_i-6\\) \\(Mujer\\): dummy que identifica a las mujeres Antes de realizar la estimación, lleve a cabo el siguiente análisis gráfico Haga un gráfico de dispersión (scatter) donde tenga los años de escolaridad en el eje X y \\(ln(w)\\) en el eje Y (use ggplot con geom_point). Interprete En una gráfica superponga la distribución empírica, densidad, de \\(ln(w)\\) para hombres y para \\(mujeres\\). Interprete los resultados Realice la estimación del modelo y reporte los resultados en una tabla bien ordenada. Interprete los coeficientes en términos de dirección, magnitud y significancia2 ¿El coeficiente estimado \\(\\hat{\\beta_1}\\) tiene interpretación causal? Explique. 2.4.2 Rendimiento en pruebas Saber 11 Es un hecho reconocido que los estudiantes de colegios oficiales tienen, en promedio, un rendimiento inferior al de los colegios privados en pruebas estandarizadas. Usando datos de la prueba SABER11 de 2020 para el departamento del Atlántico, se examinará esta cuestión. En particular, se pretende responder la pregunta ¿Cuánto es el impacto de asistir a un colegio oficial sobre el puntaje en las pruebas SABER 11? En otras palabras, cuánto del diferencial de desempeño se puede atribuir a la naturaleza del colegio. Estime el siguiente modelo \\[ Puntaje_i=\\alpha+\\beta O_i+\\mathbf{x}\\boldsymbol{\\gamma}+u_i \\] Donde la variable dependiente es punt_global y la variable explicativa de interés es una dummy que toma el valor de \\(1\\) si el colegio es oficial y 0 si es no oficial. En la base la variable para construir la dummy es cole_naturaleza. \\(\\mathbf{x}\\) Corresponde a las variables de control. Ingrese al repositorio y descargue la base saber11at.csv. Elija el conjunto de variables de control que considere relevantes. No es cualquier variable, debe haber una razón para incluirla. La idea tampoco es incluir muchas variables. Elija 5 máximo Estime el modelo sin incluir las variables de control. Interprete \\(\\hat{\\beta}\\) y analice si el estimador es insesgado. Explique detalladamente Estime el modelo con las variables de control. Interprete \\(\\hat{\\beta}\\) y compárelo con lo obtenido en el punto anterior ¿Podría darle una interpretción causal? Explique "],["endogeneidad-y-el-estimador-de-variables-instrumentales.html", "Capítulo3 Endogeneidad y el estimador de variables instrumentales 3.1 Introducción 3.2 Endogeneidad 3.3 El estimador de variables instrumentales", " Capítulo3 Endogeneidad y el estimador de variables instrumentales 3.1 Introducción El estimador MCO se dice insesgado si \\[\\begin{equation} \\tag{1} E(\\hat{\\boldsymbol{\\beta}}|\\mathbf{X})=\\boldsymbol{\\beta} \\end{equation}\\] Sabemos que este resultado requiere que \\(E(\\mathbf{u|X})=\\mathbf{0}\\). Sin embargo, hay situaciones en las que esto no es así, en tre ellas tenemos Variable omitida Error de medición Simultaneidad 3.2 Endogeneidad 3.2.1 Variable omitida En Colombia, las zonas de deforestación han coincidido con áreas de presencia de grupos armados ¿La violencia causa la deforestación? Ferguson, Romero, y Vargas (2014) intentar estimar el efecto de la expansión paramilitar sobre la deforestación. Considere la siguiente especificación \\[\\begin{equation} forest_{m,t}=\\beta_0+\\beta_1Para_{mt}+\\epsilon_{m,t} \\end{equation}\\] Donde \\(forest_{m,t}\\) es la proporción de la municipalidad \\(m\\) cubierta de bosque en el año \\(t\\), mientras que \\(Para_{m,t}\\) son los ataques paramilitares hasta el año \\(t\\) Al estimar por MCO encuentran que \\(\\hat{\\beta_1}=0.045\\) con \\(s.e=0.0117\\) ¿Podría decir que el estimador es insesgado? ¿Qué pasa si la deforestación y la presencia del conflicto dependen de las características ecológicas y geológicas del terreno? 3.2.2 Simultaneidad Usted quiere estimar el efecto de los aranceles sobre el volumen de comercio. Plantéa el siguiente modelo \\[\\begin{equation} comercio=\\beta_0+\\beta_1arancel+\\upsilon \\end{equation}\\] Sin embargo, si los grupos de presión logran hacer que el gobierno suba los aranceles como respuesta a la creciente competencia con importaciones, entonces \\[\\begin{equation} arancel=\\gamma_0+\\gamma_1comercio+\\omega \\end{equation}\\] En consecuencia \\[\\begin{equation} comercio=\\beta_0+\\beta_1(\\gamma_0+\\gamma_1comercio+\\omega)+\\upsilon \\end{equation}\\] Un choque al comercio, \\(\\upsilon\\), afecta también a los aranceles, luego \\(Cov(arancel,\\upsilon)\\neq0\\) 3.2.3 Error de Medcición Quiere estimar el efecto del ingreso familiar sobre el desempeño académico. Tiene el modelo \\[\\begin{equation} nota=\\beta_0+\\beta_1ing^*+u \\end{equation}\\] Acá, \\(ing^*\\) es la medida ideal del ingreso. Sin embargo, lo que tiene es lo que reporta el estudiante es \\(ing\\) \\[ ing=ing^*+e \\] luego \\[\\begin{align} nota&amp;=\\beta_0+\\beta_1(ing-e)+u\\\\ &amp;=\\beta_0+\\beta_1ing+\\upsilon \\end{align}\\] Con \\(\\upsilon=u-\\beta_1e\\). Note que \\(Cov(ing,\\upsilon)\\neq0\\) porque \\(ing\\) está correlacionado con \\(e\\) 3.3 El estimador de variables instrumentales Para resolver el problema de endogeneidad necesitamos exogeneidad, obvio, pero ¿Cómo? La idea básica es pensar que si \\(x_j\\) tiene una parte que está correlacionada con el error, \\(e\\), y otra que no lo está, entonces puede usarse la parte de \\(x_j\\) que no está correlacionada con el error. Para ello necesitamos un instrumento Ejemplo Feyrer (2009) quiere estimar el efecto del comercio sobre el crecimiento económico. Propone el siguiente modelo \\[\\begin{equation} lny_{it}=\\alpha+\\gamma_i+\\gamma_t+\\beta lntrade_{it}+\\epsilon_{it} \\end{equation}\\] La estimación consistente de \\(\\beta\\) requiere que \\(corr(\\epsilon_{it},lntrade_{it})=0\\). Este supuesto no es plausible, al fin y al cabo entre mayor sea el ingreso per cápita de un país mayor tenderá a ser su volúmen de importaciones y por lo tanto de comercio. Imagine que podemos descomponer la variabilidad de \\(lntrade\\) en dos partes. Una correlacionada con \\(\\epsilon\\) y otra no correlacionada \\(\\epsilon\\). Acá es donde entra el instrumento , que no es más que otra variable, \\(z\\) que debe cumplir con dos condiciones C1 No estar correlacionada con el error. Es decir, que sea exógena C2 Debe estar correlacionada con la variable endógena. Esto se conoce como condición de relevancia Feyrer (2009) propone usar el cierre del canal del Suez entre 1967 y 1975 como \\(z\\). Si el cierre fue un evento motivado principalmente por razones políticas, pero que impactó los fluos comerciales, entonces podría funcionar. En el estudo estimaron \\(\\hat{\\beta}_{OLS}=0.3(0.053)\\) y \\(\\hat{\\beta}_{IV}=0.23(0.083)\\) Note que el error estándar del estimador de variables instrumentales es mayor. Si calculamos los intervalos de confianza al 95% para cada estimación obtenemos \\(0.3\\pm 1.96(0.053)=[0.196,0.404]\\) \\(0.23\\pm 1.96(0.083)=[0.07,0.39]\\) No es evidente que la diferencia sea estadísticamente significativa. El intervalo de IV contiene la estimación por MCO 3.3.1 El Estimador IV Considere el siguiente modelo de regresión lineal \\[\\begin{equation} y=\\beta_0+\\beta_1x+e \\end{equation}\\] Sospechamos que \\(Cov(x,e)\\neq0\\) Para obtener estimadores consistentes de \\(\\beta_0\\) y \\(\\beta_1\\) necesitamos información adicional. Esta la obtenemos de \\(z\\) Z es una variable observable que debe cumplir las siguientes condiciones C1: Exogeneidad \\[ Cov(z,e)=0 \\] C2: Relevancia \\(\\pi_1\\neq0\\) en la regresión \\[ x=\\pi_0+\\pi_1z+\\upsilon \\] De donde podemos obtener \\[ \\hat{x}=\\hat{\\pi}_0+\\hat{\\pi}_1z \\] Es claro que \\(Cov(\\hat{x},e)=0\\). Luego lo usamos en \\[ y=\\beta_0+\\beta_1\\hat{x}+e$ \\] C1 No se puede probar estadísticamente C2 Se puede probar estadísticamente Además Perdemos precisión en la estimación Si \\(z\\) no cumple las condiciones, entonces puede ser peor que usar MCO Retomando \\[\\begin{equation} \\tag{1} y=\\beta_0+\\beta_1x+e \\end{equation}\\] \\[\\begin{equation} \\tag{C.1} Cov(z,e)=0 \\end{equation}\\] \\[\\begin{equation} \\tag{C.2} Cov(z,x)\\neq0 \\end{equation}\\] Usando la propiedad distributiva de la covarianza escribimos \\[\\begin{equation} \\tag{2} Cov(z,y)=\\beta_1Cov(z,x)+Cov(z,u) \\end{equation}\\] Note que bajo C.1 y C.2 podemos identificar \\(\\beta_1\\) \\[\\begin{equation} \\tag{3} \\beta_1=\\dfrac{Cov(z,y)}{Cov(z,x)} \\end{equation}\\] Usando el estimador de la covarianza, obtenemos el estimador IV \\[\\begin{equation} \\tag{4} \\hat{\\beta}_1=\\dfrac{n^{-1}\\sum_i^n(z_i-\\bar{z})(y_i-\\bar{y})}{n^{-1}\\sum_i^n(z_i-\\bar{z})(x_i-\\bar{x})} \\end{equation}\\] Usando la ley de grandes números podemos mostrar que el estimador es consistente: \\(plim(\\hat{\\beta_1})=\\beta_1\\) 3.3.2 Inferencia: necesitamos un error estándar Si suponemos \\[\\begin{equation} \\tag{5} E(e^2|z)=\\sigma^2=Var(e) \\end{equation}\\] Entonces, la varianza aintótica del estimador \\(\\hat{\\beta}_1\\) es \\[\\begin{equation} \\tag{6} \\dfrac{\\sigma^2}{n\\sigma_x^2\\rho_{x,z}} \\end{equation}\\] Y el estimador de la varianza del estimador es \\[\\begin{equation} \\tag{7} \\dfrac{\\hat{\\sigma}^2}{SST_xR^2_{x,z}} \\end{equation}\\] Note que entre menor sea la correlación de la endógena con el instrumento, mayor es la varianza del estimador. 3.3.3 Ejercicio 3.3.3.1 Motivación: Los origenes coloniales del desarrollo Acemoglu, Johnson y Robinson 3 se preguntan ¿Cuáles son las causas fundamentales de las grandes diferencias de ingreso per cápita entre paises? Los autores argumentan que mejores instituciones dan lugar a países más ricos. Los autores parten de la idea histórica según la cual en tiempos coloniales las potencias europeas realizaron dos tipos diferentes de colonización. En la primera establecieron enclaves extractivos, por ejemplo para obtener oro, y en la segunda intentaron replicar las instituciones del país de origen. Mientras que el primer tipo de colonización produce malas instituciones, el segundo produce buenas instituciones. Como consecuencia de ello, hoy día son más ricos los paises donde se dio el segundo tipo de colonización. Para examinar el efecto de las instituciones sobre el desempeño económico los autores proponen estimar el siguiente modelo \\[\\begin{equation} log y_i=\\mu+\\alpha R_i+\\mathbf{X}&#39;_i\\boldsymbol{\\gamma}+\\epsilon_i \\end{equation}\\] Donde \\(log y_i\\) es el ingreso per cápita del país i en 1995, \\(R_i\\) es una medida de riesgo de expropiación y \\(\\mathbf{X}_i\\) es un vector de variables de control. La variable \\(R_i\\), avexpr, es un índice que mide la protección contra la expropiación, y por lo tanto captura las diferencias institucionales entre paises. En aquellos paises donde los derechos de propiedad privados se respetan el valor del índice es mayor, máximo 10, mientras que en un país donde los derechos de propiedad no son protegidos en absoluto el valor es 0. El coeficiente \\(\\alpha\\) es el interés de la investigación. 3.3.3.2 Procedimiento Cargue la base de datos colonial.dta en R. Restrinja la muestra solo para los paises que son excolonias y tienen los datos completos, baseco=1. Estime la ecuación (1) por MCO, donde la variable dependiente es logpgp95 y \\(R_i\\) es avexpr. Como variables de control incluya lat_abst: distancia absoluta al ecuador, escalado entre 0 y 1 asia: dummy para Asia africa: dummy para África other: dummy para otro continente. Toman el valor de 1 los siguientes países: Australia (AUS), Malta (MLT), y Nueva Zelanda (NZL). Las dummies de continente tienen como categoría base América Table 1.1: Regresión MCO coefficient Std. Error t-value p-value (Intercept) 5.737 0.398 14.407 0.000 avexpr 0.401 0.059 6.788 0.000 lat_abst 0.875 0.628 1.393 0.169 asia -0.577 0.231 -2.493 0.016 africa -0.881 0.170 -5.181 0.000 other 0.107 0.382 0.280 0.780 Los autores indican que si bien los resultados van en la dirección esperada, el parámetro de interés \\(\\alpha\\) no se estima consistentemente por MCO ¿Por qué? Los autores proponenen usar como instrumento la tasa de mortalidad de los colonizadores europeos, en logaritmo, logem4 ¿Cuál es la lógica de este instrumento? El instrumento debe cumplir dos condiciones para que permita identificar el parámetro de interés. Indique cuales son los dos supuestos y pruebe econométricamente el que se puede probar. Estime el modelo usando el estimador de variables instrumentales. Compare los resultados del coeficiente de interés entre los modelos MCO y IV. Interprete los resultados Table 3.1: Estimador IV coefficient Std. Error t-value p-value (Intercept) 1.4405 2.8396 0.5073 0.6139 avexpr 1.1071 0.4636 2.3881 0.0202 lat_abst -1.1782 1.7554 -0.6712 0.5048 asia -1.0471 0.5246 -1.9961 0.0506 africa -0.4373 0.4242 -1.0308 0.3069 other -0.9904 0.9980 -0.9924 0.3251 Como siempre, las estimaciones por IV dependen de la calidad de los instrumentos. Lea el comentario de Albouy (2012)4 y explique de manera brece y clara porque las estimaciones podrían sufirir del problema de instrumentos débiles "],["modelos-de-elección-discreta.html", "Capítulo4 Modelos de elección discreta 4.1 Naturaleza del problema 4.2 El modelo de probabilidad lineal 4.3 Modelos Logit y Probit 4.4 Ejercicio de aplicación 4.5 Estimaciones", " Capítulo4 Modelos de elección discreta 4.1 Naturaleza del problema Muchos fenómenos económicos tienen que ver con decisiones que toman los agentes. Por ejemplo, si decide cursar estudios universitarios, \\(y=1\\) o no, \\(y=0\\). Implica que para una muestra de datos podemos calcular la proporción de individuos que tomaron cada decisión. Esto sería el chance de que ocurra el evento A partir de los axiomas que definen la probabilidad, podemos deducir a partir de la probabilidad de un evento, \\(P(A)\\), la probablidad de otro evento, \\(P(B)\\) Nos interesa modelar la probabilidad de ocurrencia del evento, la decisión, dadas determinadas circunstancias 4.2 El modelo de probabilidad lineal La variable dependiente representa la elección entre dos alternativas, A y B, para cada individuo \\(i\\) se representa como \\[ \\tag{1} y_i= \\begin{cases} 1,&amp; \\text{Si la alternativa A se elige}\\\\ 0, &amp; \\text{Si la alternativa B se elige} \\end{cases} \\] Escribimos el modelo como \\[ \\tag{2} y=\\beta_0+\\beta_1x_1+\\beta_2x_2+...+\\beta_3x_3+u \\] Tomamos el valor esperado condicional \\[ E(y|\\mathbf{x})=\\beta_0+\\beta_1x_1+...+\\beta_kx_k+E(u|\\mathbf{x}) \\] Además, dada la naturaleza de \\(y\\) \\[ \\tag{3} E(y|\\mathbf{x})=P(y=1|\\mathbf{x})1+(1-P(y=1|\\mathbf{x}))0 \\] Si, además se cumple exogeneidad estricta \\(E(u|\\mathbf{x})\\), entonces \\[ \\tag{4} P(y=1|\\mathbf{x})=\\beta_0+\\beta_1x_1+...+\\beta_kx_k \\] En este modelo \\[ \\beta_j=\\dfrac{\\Delta P(y=1|\\mathbf{x})}{\\Delta x_j} \\] Los parámetros los estimamos por MCO, y a partir de ello podemos obtener la probabilidad predicha \\[ \\hat{y}=\\hat{P}(y=1|\\mathbf{x})=\\hat{\\beta_0}+\\hat{\\beta}_1x_1+...+\\hat{\\beta}_kx_k \\] 4.2.1 Ejemplo \\[ Auto_i= \\begin{cases} 1,&amp; \\text{Va en automóvil}\\\\ 0, &amp; \\text{Va en bus} \\end{cases} \\] Estima \\[ \\hat{Auto}=0.48+0.0703T \\] Donde \\(T=(TBus-TAuto)/10\\) es el tiempo de desplazamiento en bus en relación al desplazamiento en automóvil Si \\(T=0\\) entonces la probabilidad de ir en automóvil es 0.48 Si \\(T\\) pasa de \\(0\\) a \\(1\\), entonces la probabilidad se incrementa de \\(0.48\\) a \\(0.55\\) Probablidades por fuera del rango 0-1 4.2.2 Heterocedasticidad en el LPM Si \\(y_i=1\\) entonces \\(\\beta_0+\\beta_{i1}x_1+...+\\beta_kx_{ik}+u_i=1\\), luego \\[\\begin{equation} u_i=1-(\\beta_0+\\beta_1x_{i1}+...+\\beta_kx_{ik}) \\end{equation}\\] Y si \\(y_i=0\\) \\[\\begin{equation} u_i=-(\\beta_0+\\beta_1x_{i1}+...+\\beta_kx_{ik}) \\end{equation}\\] Luego \\(u_i\\) toma dos valores, por lo tanto su varianza es \\[ Var(u|\\mathbf{x})=P(X=1|\\mathbf{x})[1-P(X=1|\\mathbf{x})]=\\sigma_i^2 \\] Es heterocedástica pues depende de los valores de \\(x\\). Debemos usar errores estándar robustos 4.3 Modelos Logit y Probit 4.3.1 Especificación En el modelo de probabilidad lineal modelamos la probabilidad de ocurrencia \\[ P(y=1|\\mathbf{x})=\\beta_0+\\beta_1x_1+...+\\beta_kx_k \\] Sin embargo, sabemos que podemos obtener predicciones por fuera del intervalo \\((0,1)\\). Para solucionarlo, usamos una función \\(0&lt;G(z)&lt;1\\) para todos los números reales \\(z\\) \\[ \\tag{5} P(y=1|\\mathbf{x})=G(\\beta_0+\\beta_1x_1+...+\\beta_kx_k) \\] Se suelen usar dos funciones de dsitribución acumulada para \\(G\\): logística, normal. Recuerde que la CDF de la variable aleatoria \\(\\mathbf{x}\\) es \\(F_x(x)=P(\\mathbf{x}\\leq x)\\) Logística \\[ \\tag{6} G(z)=\\dfrac{e^z}{1+e^z}=\\Lambda(z) \\] Normal \\[ \\tag{7} G(z)=\\Phi(z)=\\int_{\\infty}^z \\phi(v)dv \\] Donde \\[ \\phi(z)=(2\\pi)^{-1/2}e^{(-z^2/2)} \\] 4.3.2 Función acumulada de distribución (CDF) 4.3.3 Función acumulada de distribución (pdf) \\(f_x(x)=\\dfrac{F_x(x)}{dx}\\) 4.3.4 Probablilidad predicha: LPM vs Probit \\(\\hat{Auto}=\\Phi(-0.0064+0.3T)\\) 4.3.5 Interpretación: efectos marginales Llamamos \\(p(\\mathbf{x})=P(y=1|\\mathbf{x})\\). Queremos calcular el cambio en la probabilidad de ocurrencia dado un cambio en \\(x_j\\). Variable Continua \\[ \\tag{7} \\dfrac{\\partial p(\\mathbf{x})}{\\partial x_j}=\\dfrac{\\partial G(z)}{\\partial z}\\beta_j \\] Para la logística es \\[ \\dfrac{\\partial G(z)}{\\partial z}=\\dfrac{e^z}{(1+e^z)^2} \\] Para la normal \\[ \\dfrac{\\partial G(z)}{\\partial z}=\\phi(z) \\] Variable Discreta Digamos que \\(x_1\\) toma valores de \\(0\\) y \\(1\\) \\[ \\Delta p(\\mathbf{x})=G(\\beta_0+\\beta_1+\\beta_2x_2+...+\\beta_kx_k)-G(\\beta_0+\\beta_2x_2+...+\\beta_kx_k) \\] En cualquier caso debemos decidir los valores de \\(\\mathbf{x}\\) en los que evaluamos la función \\(G\\). Tenemos 3 opciones 1. MEM: Efecto marginal en la media \\(\\bar{\\mathbf{x}}=(\\bar{x_1},...,\\bar{x}_k)\\) 2. MER: Valor marginal en el un valor representativo: escoge los valores de \\(\\mathbf{x}\\) que quiera 3. AME: Efecto marginal promedio. Promediamos los efectos marginales individuales en la muestra. Este valor es similar al que se obtiene por LPM 4.3.5.1 AME En el caso de variable continua \\[\\begin{equation} AME(x_j)=n^{-1}\\beta_j\\sum_{i=1}^n g(\\beta_0+\\beta_1x_{i1}+\\beta_2x_{i2}+...+\\beta_kx_{ik}) \\end{equation}\\] Donde \\(g(z)=\\dfrac{\\partial G(z)}{\\partial z}\\) En el caso de variable discreta, supongamos \\(x_1\\) es una dummy \\[\\begin{equation} AME(x_1)=n^{-1}\\sum_{i=1}^n\\Big(G(\\beta_0+\\beta_1+...+\\beta_kx_k)-G(\\beta_0+...+\\beta_kx_k) \\Big) \\end{equation}\\] Es decir que para cada individuo se estima la probabilidad cuando \\(x_1=1\\) y cuando \\(x_1=0\\) y se toma la diferencia. En la terminología de contrafactuales esto sería el efecto de tratamiento promedio. 4.3.6 Medidas de ajuste Correctamente predicho \\[ ACC=\\dfrac{TP+TN}{TP+TN+FP+FN} \\] Sensibilidad (Tasa de verdadero positivo) \\[ S=\\dfrac{TP}{TP+FN}=\\dfrac{TP}{P} \\] Especificidad (tasa de verdadero negativo) \\[ SP=\\dfrac{TN}{TN+FP}=\\dfrac{TN}{N} \\] 4.4 Ejercicio de aplicación En la industria crediticia es muy importante identificar los factores que pueden dar lugar a que los deudores no honren a tiempo sus obligaciones, es decir que entren en default. Para ello usaremos los datos vegas5.xlsx que hacen parte del libro de texto Principles of Econometrics5. Las variables son las siguientes default: 1 si el individuo se ha retrasado en más de 90 días, 0 si no se ha retrasado. Esta es la variable dependiente arm: dummy que indica si la tasa de interés es ajustable refinance: 1 si el crédito es para refinanciar o si es para compra de inmueble lien2: Si hay un segundo lien hipotecario toma el valor de 1, 0 si es el primer lien. Un lien hipotecario es el derecho que tiene el prestamista de tomar posesión del inmueble si el deudor entra en cesasión de pagos. term30: 1 si el plazo es de 30 años, 0 si es de 15 años underwater: 1 si la deduda se estima en un valor mayor que el de la propiedad en el momento de originar el crédito LTV: loan to value de la propiedad, en porcentaje rate: tasa de interés sobre la deuda, porcentaje amount: valor del crédito en unidades de \\(\\$10,000\\) fico: puntaje de crédito al momento de otorgamiento del crédito. 4.5 Estimaciones 1. Modelo de probabilidad lineal: estime la siguiente ecuación por MCO y con errores estándar robustos \\[ default=\\beta_0+\\beta_1arm+\\beta_2refinance+\\beta_3lien2+\\beta_4term30+\\beta_5underwater+\\beta_6ltv+\\beta_7rate+\\beta_8amount+\\beta_9fico+e \\] Table 4.1: LPM coefficient Std. Error t-value p-value (Intercept) 0.451 0.069 6.503 0.000 arm -0.024 0.010 -2.379 0.017 refinance -0.048 0.010 -4.965 0.000 lien2 0.182 0.026 6.962 0.000 term30 -0.017 0.014 -1.223 0.221 underwater 0.178 0.019 9.199 0.000 ltv 0.005 0.000 11.947 0.000 rate 0.040 0.003 15.484 0.000 amount 0.000 0.000 -0.988 0.323 fico -0.001 0.000 -15.049 0.000 Verifiquemos el comportamiento de los residuales. Hagamos la prueba de Breush-Pagan bptest(lpm1) studentized Breusch-Pagan test data: lpm1 BP = 772.52, df = 9, p-value &lt; 2.2e-16 Dado que tenemos evidencia de heterocedasticidad, procedemos a estimar el modelo con errores estándar robustos lpm1r&lt;-coeftest(lpm1, vcov = vcovHC(lpm1, type=&quot;HC1&quot;)) kable(tidy(lpm1r), digits=4, align=&#39;c&#39;,caption= &quot;LPM&quot;, col.names=c(&quot;&quot;,&quot;coefficient&quot;, &quot;Robust Std. Error&quot;, &quot;t-value&quot;, &quot;p-value&quot;)) Table 4.2: LPM coefficient Robust Std. Error t-value p-value (Intercept) 0.4514 0.0681 6.6252 0.0000 arm -0.0239 0.0102 -2.3374 0.0194 refinance -0.0483 0.0097 -4.9711 0.0000 lien2 0.1821 0.0234 7.7859 0.0000 term30 -0.0174 0.0139 -1.2553 0.2094 underwater 0.1782 0.0147 12.1381 0.0000 ltv 0.0050 0.0004 13.0408 0.0000 rate 0.0400 0.0026 15.5933 0.0000 amount -0.0002 0.0002 -1.2463 0.2127 fico -0.0011 0.0001 -15.3711 0.0000 Interprete los coeficientes 2. Estime el modelo logit Call: glm(formula = default ~ arm + refinance + lien2 + term30 + underwater + ltv + rate + amount + fico, family = &quot;binomial&quot;, data = vegas5) Deviance Residuals: Min 1Q Median 3Q Max -2.1174 -0.9403 -0.6598 1.1405 2.7382 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -0.8306594 0.3495402 -2.376 0.01748 * arm -0.1434127 0.0483486 -2.966 0.00301 ** refinance -0.2404201 0.0476051 -5.050 4.41e-07 *** lien2 1.2776049 0.1580227 8.085 6.22e-16 *** term30 -0.0698832 0.0724898 -0.964 0.33503 underwater 1.2418800 0.1213201 10.236 &lt; 2e-16 *** ltv 0.0254911 0.0021861 11.660 &lt; 2e-16 *** rate 0.1906607 0.0128088 14.885 &lt; 2e-16 *** amount -0.0013225 0.0013039 -1.014 0.31045 fico -0.0052253 0.0003692 -14.154 &lt; 2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 13178 on 9999 degrees of freedom Residual deviance: 11912 on 9990 degrees of freedom AIC: 11932 Number of Fisher Scoring iterations: 4 2. Estime el modelo probit Call: glm(formula = default ~ arm + refinance + lien2 + term30 + underwater + ltv + rate + amount + fico, family = binomial(link = &quot;probit&quot;), data = vegas5) Deviance Residuals: Min 1Q Median 3Q Max -2.1129 -0.9454 -0.6634 1.1448 2.9244 Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -0.3908903 0.2085569 -1.874 0.06089 . arm -0.0844379 0.0293512 -2.877 0.00402 ** refinance -0.1484383 0.0287391 -5.165 2.4e-07 *** lien2 0.7400364 0.0890195 8.313 &lt; 2e-16 *** term30 -0.0374059 0.0432364 -0.865 0.38696 underwater 0.7168854 0.0671228 10.680 &lt; 2e-16 *** ltv 0.0150133 0.0012924 11.617 &lt; 2e-16 *** rate 0.1140099 0.0076793 14.846 &lt; 2e-16 *** amount -0.0007109 0.0007626 -0.932 0.35122 fico -0.0032324 0.0002224 -14.531 &lt; 2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 13178 on 9999 degrees of freedom Residual deviance: 11914 on 9990 degrees of freedom AIC: 11934 Number of Fisher Scoring iterations: 5 4. Calcule el efecto marginal promedio para los modelos logit y probit. Use el paquete margins library(margins) marglogit&lt;-margins(mlogit) marprobit&lt;-margins(mprobit) summary(marglogit) factor AME SE z p lower upper amount -0.0003 0.0003 -1.0145 0.3104 -0.0008 0.0003 arm -0.0295 0.0099 -2.9705 0.0030 -0.0489 -0.0100 fico -0.0011 0.0001 -14.7146 0.0000 -0.0012 -0.0009 lien2 0.2624 0.0322 8.1595 0.0000 0.1994 0.3254 ltv 0.0052 0.0004 11.9523 0.0000 0.0044 0.0061 rate 0.0392 0.0025 15.5250 0.0000 0.0342 0.0441 refinance -0.0494 0.0097 -5.0733 0.0000 -0.0685 -0.0303 term30 -0.0144 0.0149 -0.9642 0.3349 -0.0435 0.0148 underwater 0.2551 0.0246 10.3823 0.0000 0.2069 0.3032 summary(marprobit) factor AME SE z p lower upper amount -0.0002 0.0003 -0.9323 0.3512 -0.0007 0.0003 arm -0.0287 0.0099 -2.8800 0.0040 -0.0482 -0.0092 fico -0.0011 0.0001 -15.0092 0.0000 -0.0012 -0.0010 lien2 0.2511 0.0300 8.3826 0.0000 0.1924 0.3099 ltv 0.0051 0.0004 11.8467 0.0000 0.0043 0.0059 rate 0.0387 0.0025 15.3497 0.0000 0.0338 0.0436 refinance -0.0504 0.0097 -5.1848 0.0000 -0.0694 -0.0313 term30 -0.0127 0.0147 -0.8653 0.3869 -0.0414 0.0161 underwater 0.2433 0.0225 10.8258 0.0000 0.1992 0.2873 5. Matriz de confusión vegas5&lt;-vegas5%&gt;%mutate(yhat=predict(mlogit,type=&quot;response&quot;)) vegas5&lt;-vegas5%&gt;%mutate(defpred=ifelse(yhat&gt;0.5,1,0)) table(vegas5$default,vegas5$defpred) 0 1 0 5427 874 1 2304 1395 "],["modelos-con-datos-temporales-introducción.html", "Capítulo5 Modelos con datos temporales: Introducción 5.1 Introducción 5.2 Autocorrelaciones Ejercicio", " Capítulo5 Modelos con datos temporales: Introducción 5.1 Introducción Una serie de tiempo es un proceso ordenado secuencialmente en el tiempo. Decimos que \\(t\\) es un entero que denota el periodo de tiempo. La mayoría de las series de tiempo de variables económicas se registran a intervalos discretos: anual, trimestral, mensual, diario. Decimos que el número de periodos observados por año define la frecuencia de la serie. Un aspecto crucial es la dependencia temporal de las observaciones qeu están cercanas en tiempo calendario. Por ejemplo, la tasa de inflación de junio está relacionada con la tasa de inflación de mayo. 5.1.1 Ejemplos library(fpp3) library(readxl) library(ggpubr) piby&lt;- read_excel(here(&quot;Econometria2&quot;,&quot;Data&quot;,&quot;pibyear.xlsx&quot;)) piby&lt;-tsibble(piby,index=year) pib.plot&lt;-ggplot(piby,aes(x=year,y=rgdpo))+geom_line()+labs(title=&quot;PIB&quot;, y=&quot;USD (millones 2011)&quot;,x=&quot;&quot;)+theme_minimal() piby&lt;-piby%&gt;%mutate(gpib=difference(log(rgdpo),lag=1)*100) gpib.plot&lt;-ggplot(piby,aes(x=year,y=gpib))+geom_line()+labs(title=&quot;Crecimiento&quot;,y=&quot;%&quot;,x=&quot;&quot;,caption=&quot;Penn World Tables&quot;)+theme_minimal()+geom_hline(yintercept=0) ggarrange(pib.plot,gpib.plot,ncol=2) mes&lt;- read_excel(here(&quot;Econometria2&quot;,&quot;Data&quot;,&quot;tsmonth.xlsx&quot;)) mes&lt;-mes%&gt;%mutate(date=yearmonth(date))%&gt;%as_tsibble(index=date) ipc.plot&lt;-ggplot(mes,aes(x=date,y=ipc))+geom_line()+labs(title=&quot;IPC&quot;,y=&quot;&quot;,x=&quot;&quot;)+theme_minimal() inf.plot&lt;-mes%&gt;%mutate(inf=difference(log(ipc),lag=1)*100)%&gt;%ggplot(aes(x=date,y=inf))+geom_line()+theme_minimal()+labs(title=&quot;Inflación Mensual&quot;,x=&quot;&quot;,y=&quot;&quot;,caption=&quot;DANE&quot;) ggarrange(ipc.plot,inf.plot,ncol=2) mes%&gt;%mutate(inf=difference(log(ipc),lag=1)*100)%&gt;% gg_season(inf,labels=&quot;both&quot;)+ labs(y=&quot;%&quot;,title=&quot;Gráfico estacional: inflación mensual&quot;,x=&quot;&quot;) ipcdcmp&lt;-mes%&gt;%model(stl=STL(ipc)) components(ipcdcmp)%&gt;%autoplot() wti.plot&lt;-ggplot(mes,aes(x=date,y=wti))+geom_line()+labs(title=&quot;WTI&quot;,y=&quot;US$/barril&quot;,x=&quot;&quot;)+theme_minimal() gwti.plot&lt;-mes%&gt;%mutate(gwti=difference(log(wti),lag=1)*100)%&gt;%ggplot(aes(x=date,y=gwti))+geom_line()+theme_minimal()+labs(title=&quot;Var mes WTI&quot;,x=&quot;&quot;,y=&quot;%&quot;,caption=&quot;IEA&quot;) ggarrange(wti.plot,gwti.plot,ncol=2) trm&lt;- read_excel(here(&quot;Econometria2&quot;,&quot;Data&quot;,&quot;tsdaily.xlsx&quot;)) trm&lt;-trm%&gt;%mutate(date=ymd(date))%&gt;%as_tsibble(index=date) trm.plot&lt;-ggplot(trm,aes(x=date,y=trm))+geom_line()+labs(title=&quot;TRM&quot;,y=&quot;COP/USD&quot;,x=&quot;&quot;)+theme_minimal() dep.plot&lt;-trm%&gt;%mutate(dep=difference(log(trm),lag=1)*100)%&gt;%ggplot(aes(x=date,y=dep))+geom_line()+theme_minimal()+labs(title=&quot;Depreciación&quot;,x=&quot;&quot;,y=&quot;%&quot;,caption=&quot;BanRep&quot;) ggarrange(trm.plot,dep.plot,ncol=2) 5.2 Autocorrelaciones Para explorar el grado de dependencia entre la variable en el periodo \\(t\\) y sus rezagos, \\(t-s\\), usamos el coeficiente de correlación \\[ \\rho_s=\\dfrac{Cov(X_t,X_{t-s})}{Var(X_t)} \\] Cuyo estimador muestral es \\[ \\hat{\\rho}_s=\\dfrac{\\sum_{t=s+1}^{T}(X_t-\\bar{X})(X_{t-s}-\\bar{X})}{\\sum_{t=1}^{T}(X_t-\\bar{X})^2} \\] acfpib&lt;-piby%&gt;%ACF(rgdpo)%&gt;%autoplot()+labs(title=&quot;ACF PIB&quot;) acfgpib&lt;-piby%&gt;%ACF(gpib)%&gt;%autoplot()+labs(title=&quot;ACF Crecimiento PIB&quot;) ggarrange(acfpib,acfgpib,ncol=2) acfipc&lt;-mes%&gt;%mutate(lipc=log(ipc))%&gt;%ACF(lipc,lag_max=48)%&gt;%autoplot()+labs(title=&quot;ACF Ln IPC&quot;) acfinf&lt;-mes%&gt;%mutate(inf=difference(log(ipc),lag=1))%&gt;%ACF(inf,lag_max=48)%&gt;%autoplot()+labs(title=&quot;ACF Inflación&quot;) ggarrange(acfipc,acfinf,ncol=2) acftrm&lt;-trm%&gt;%mutate(ltrm=log(trm))%&gt;%ACF(ltrm)%&gt;%autoplot()+labs(title=&quot;ACF Ln TRM&quot;) acfdep&lt;-trm%&gt;%mutate(dep=difference(log(trm),lag=1))%&gt;%ACF(dep)%&gt;%autoplot()+labs(title=&quot;ACF Depreciación&quot;) ggarrange(acftrm,acfdep,ncol=2) Ejercicio Para cada una de las series realice un análisis gráfico, lo que incluye la autocorrelación, de las variables en niveles y en diferencias. Trabaje con la serie en logaritmo cuando lo considere relevante ISE: índice de Seguimiento de la Economía. Serie de frecuencia mensual publicada por el DANE Tasa de desempleo total nacioanl. Serie de frecuencia mensual publidada por el DANE Precio de cierre de Bitcoin. Serie de frecuencia diaria. Se sugiere descargar los datos de Yahoo Finance usando el paquete quantmod En el siguiente capítulo lo elaboramos en detalle Se sugiere revisar https://documents1.worldbank.org/curated/en/830831468147839247/pdf/WPS7020.pdf Acemoglu, Johnosn y Robinson, 2001, The colonial origins of comparative development: an empirical investigation, The American Economic Review, Vol. 95, 5, http://economics.mit.edu/files/4123 Albouy, D., 2012, The colonial origins of comparative development: an empirical investigation: comment, The American Economic Review, Vol 102(6)  Carter, Griffiths, Lim, 2017, Principles of econometrics, 5th ed., Wiley &amp; Sons "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
